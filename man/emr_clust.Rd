% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/emr_clust.R, R/fun_emr_clust.R
\name{emr_clust}
\alias{emr_clust}
\title{Feature selection + dimention reduction + clustering}
\usage{
emr_clust(
  data,
  group,
  center = TRUE,
  scale = TRUE,
  kmoCutoff,
  method = c("RKM", "FKM", "clusCA", "iFCB", "MCAk", "PCA", "SVD", "TSNE", "MDS", "MCA",
    "Kmedoid", "Kmean"),
  nclus,
  ndim,
  nstart = 10,
  rotation = "none",
  alphak = 0.5,
  criterion = c("asw", "ch", "crit"),
  dst = c("full", "low"),
  perplexity = 30,
  theta = 0.4,
  distMethod = c("euclidean", "manhattan"),
  seed = NULL,
  pc.params = NULL,
  attr.params = NULL,
  text.params = NULL,
  cluster_color_set = NULL,
  bar.params = NULL,
  choose_group = NULL
)
}
\arguments{
\item{data}{Dataset with metric variables.}

\item{group}{to choose data gruup.}

\item{center}{a logical value indicating whether the variables should be shifted to be zero centered. Alternately, a vector of length equal the number of columns of x can be supplied. The value is passed to \code{scale} (default = TRUE).}

\item{scale}{a logical value indicating whether the variables should be scaled to have unit variance before the analysis takes place. The default is FALSE for consistency with S, but in general scaling is advisable. Alternatively, a vector of length equal the number of columns of x can be supplied (default = TRUE).}

\item{kmoCutoff}{KMO test(Kaiser–Meyer–Olkin test).}

\item{method}{Specifies the method. Combine methods: \code{RKM} for reduced K-means, \code{FKM} for factorial K-means, \code{MCAk} for MCA K-means, \code{iFCB} for Iterative Factorial Clustering of Binary variables and \code{clusCA} for Cluster Correspondence Analysis.Seperated methods: Dimension reduction methods \code{PCA} for Principal Component Analysis, \code{SVD} for Singular Value Decomposition, \code{TSNE} for t-distributed Stochastic Neighbor Embedding, \code{MDS} for Multidimensional Scaling and \code{MCA} for Multiple correspondence analysis. Clustering methods \code{Kmedoid}, \code{Kmean}.}

\item{nclus}{Number of clusters .}

\item{ndim}{Dimensionality of the solution.}

\item{nstart}{Number of starts (default = 50).}

\item{rotation}{Specifies the method used to rotate the factors.}

\item{alphak}{Non-negative scalar to adjust for the relative importance of MCA (alphak = 1) and K-means (alphak = 0) in the solution (default = .5). Works only in combination with method = \code{MCAk}.}

\item{criterion}{One of \code{asw},\code{ch}, \code{crit}. Determines whether average silhouette width, Calinski-Harabasz index ,criterion value or objective value of the selected method is used (default = \code{asw}).}

\item{dst}{Specifies the data used to compute the distances between objects. Options are \code{full} for the original data (after possible scaling) and \code{low} for the object scores in the low-dimensional space (default = \code{full}).}

\item{perplexity}{for dimension reduction method \code{TSNE}; numeric; Perplexity parameter (should not be bigger than 3 * perplexity < nrow(X) - 1, see details for interpretation).}

\item{theta}{for dimension reduction method \code{TSNE}; numeric; Speed/accuracy trade-off (increase for less accuracy), set to 0.0 for exact TSNE (default: 0.5).}

\item{distMethod}{the distance measure to be used. This must be one of \code{euclidean},\code{manhattan}. Any unambiguous substring can be given.}

\item{seed}{An integer that is used as argument by \code{set.seed()} for offsetting the random number generator.}

\item{pc.params}{to adjust ggplot clustering_biplots.}

\item{attr.params}{to adjust ggplot clustering_biplots.}

\item{text.params}{to adjust ggplot clustering_biplots.}

\item{cluster_color_set}{to adjust ggplot biplot.}

\item{bar.params}{to adjust ggplot profile_by_cluster_integrated & profile_by_group_integrated.}

\item{choose_group}{to adjust ggplot only show the parameter want to see.}
}
\value{
clust data

\code{list}.
\enumerate{
\item \code{clust_out}: Simple output data table including tuning output table.
\item \code{statistic_table}: Complete dimention reduction and clustering table with Descriptive statistics table.
\item \code{biplot}: Result presentation for clustering results.Including Biplot of the first and second principal components,the number and proportion of case in each cluster and the number and proportion of case in each group.
}
}
\description{
These function can handle numerical and categorical data
}
\details{
\code{emr_clust} can be used for doing feature selection + dimention reduction + clustering with data Visualization.
the data input should be a data frame object in R, and contain at least one cluster coloumn.
Also, if inputting categorical dataset make sure it has already been converted into Binary factor datasets.
}
\examples{
#for categorical dataset with combine dimention reduction & clustering method example
library(FactoMineR)
data(tea)
# I. Data doing feature selection + dimention reduction + clustering with result presentation for distribution of variables
emr_cat<-emr_clust(tea[,1:13],
                   method =c("MCAk"),
                   kmoCutoff = 0.5,
                   nclus=c(4:5),
                   ndim=c(2:3),
                   group="Tea",
                   nstart=50)
#show the tuning output table
knitr::kable(head(emr_cat$clust_out$tune_table),"pipe")
#show the statistic table
knitr::kable(head(emr_cat$statistics_table$PC_data),"pipe")
knitr::kable(head(emr_cat$statistics_table$attr_data),"pipe")
knitr::kable(head(emr_cat$statistics_table$use_table),"pipe")
#Biplot of the first and second principal components
emr_cat$biplot$clustering_biplots
#Profile the number and proportion of case in each cluster
emr_cat$biplot$profile_by_cluster_integrated
#Profile the number and proportion of case in each group
emr_cat$biplot$profile_by_group_integrated
}
